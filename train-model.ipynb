{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emerging Technologies Project 2020\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Instructions\n",
    "\n",
    "In this project you must create a web service that uses machine learning to make predictions based on the data set powerproduction available on Moodle. The goal is to\n",
    "produce a model that accurately predicts wind turbine power output from wind speed\n",
    "values, as in the data set. You must then develop a web service that will respond with\n",
    "predicted power values based on speed values sent as HTTP requests. Your submission\n",
    "must be in the form of a git repository containing, at a minimum, the following items:\n",
    "1. Jupyter notebook that trains a model using the data set. In the notebook you\n",
    "should explain your model and give an analysis of its accuracy.\n",
    "2. Python script that runs a web service based on the model, as above.\n",
    "3. Dockerfile to build and run the web service in a container.\n",
    "4. Standard items in a git repository such as a README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific computing with Python\n",
    "import numpy as np\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Data frames.\n",
    "import pandas as pd\n",
    "# machine learning\n",
    "import tensorflow\n",
    "# importing keras from tensorflow package used for deeplearning\n",
    "from tensorflow import keras\n",
    "# Shuffle arrays or sparse matrices in a consistent way.\n",
    "from sklearn.utils import shuffle\n",
    "# import keras sequential model.\n",
    "from tensorflow.keras.models import Sequential\n",
    "# importing keras layers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "# importing optimizers.\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# importing metrics for accuracy calc\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "# Set data type to float64.\n",
    "keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "Keras is a deep learning API written in Python, running on top of the machine learning platform TensorFlow.Keras is the high-level API of TensorFlow 2.0: an approchable, highly-productive interface for solving machine learning problems, with a focus on modern deep learning. It provides essential abstractions and building blocks for developing and shipping machine learning solutions with high iteration velocity [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "Neural Networks are used to solve a lot of challenging artificial intelligence problems. They often outperform traditional machine learning models because they have the advantages of non-linearity, variable interactions, and customizability [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & Visualizing PowerProduction DataSet\n",
    "\n",
    "In order to better grasp the data we deal with, we need to load and visualize it. This gives us some insights into the data and allows us to suit a better Neural Network. To read the dataset, we use Pandas and to map it, Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read data from data.csv into pandas dataframe.\n",
    "df = pd.read_csv('powerproduction.csv')\n",
    "X, y = df['speed'], df['power']\n",
    "\n",
    "# Plot data to visualize it.\n",
    "plt.plot(X, y, 'g+')\n",
    "plt.title('Power Production')\n",
    "plt.xlabel('speed')\n",
    "plt.ylabel('power')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train And Test\n",
    "\n",
    "We need to provide the Keras Neural Network with training and testing datasets, so we split the dataset into two distributions, one for training **80 %** and one for testing **20 %**.To prevent overfitting or learning a pattern, we shuffle and normalize the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, test and validation distributions.\n",
    "df = shuffle(df)\n",
    "X_train, y_train = df['speed'][:400], df['power'][:400]\n",
    "X_test, y_test = df['speed'][400:], df['power'][400:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Fitting\n",
    "\n",
    "We can now build and train a neural network after splitting data into training and test sets. We will use three dense layers of a sequential model. The first layer contains 128 neurons and the activation function of RELU, the second layer contains 256 neurons and the activation function of RELU, and the output layer contains only one neuron. In order to prevent overfitting, this model also utilizes dropouts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor [6]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Layers\n",
    "\n",
    "Layers are the basic building blocks of neural networks in Keras.A layer consists of a tensor-in tensor-out computation function (the layer's call method) and some state, held in TensorFlow variables (the layer's weights) [7]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Why use ReLU (Rectified Linear Activation Function)?\n",
    " \n",
    "The ReLU [11] function is another non-linear activation function that has gained popularity in the deep learning domain. ReLU stands for Rectified Linear Unit. The main advantage of using the ReLU function over other activation functions is that it does not activate all the neurons at the same time.\n",
    "This means that the neurons will only be deactivated if the output of the linear transformation is less than 0. The plot below will help you understand this better-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Optimizer\n",
    "An optimizer is one of the two arguments required for compiling a Keras model.\n",
    "Optimizer that implements the Adam algorithm [8].\n",
    "### Adam Optimizer\n",
    "Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order \n",
    "and second-order moments [9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "13/13 [==============================] - 1s 14ms/step - loss: 3363.4391 - val_loss: 2239.4281\n",
      "Epoch 2/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1939.1871 - val_loss: 803.1316\n",
      "Epoch 3/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 728.7606 - val_loss: 354.1735\n",
      "Epoch 4/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 866.3775 - val_loss: 352.8580\n",
      "Epoch 5/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 636.7413 - val_loss: 370.4936\n",
      "Epoch 6/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 619.1413 - val_loss: 360.5342\n",
      "Epoch 7/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 553.8717 - val_loss: 357.3822\n",
      "Epoch 8/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 633.0940 - val_loss: 367.2892\n",
      "Epoch 9/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 552.9984 - val_loss: 350.5469\n",
      "Epoch 10/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 584.9859 - val_loss: 365.6225\n",
      "Epoch 11/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 682.6450 - val_loss: 345.9296\n",
      "Epoch 12/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 604.0784 - val_loss: 344.5835\n",
      "Epoch 13/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 651.4715 - val_loss: 352.4774\n",
      "Epoch 14/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 568.9810 - val_loss: 340.1774\n",
      "Epoch 15/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 490.6790 - val_loss: 338.4419\n",
      "Epoch 16/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 609.6549 - val_loss: 346.8334\n",
      "Epoch 17/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 605.5634 - val_loss: 349.2800\n",
      "Epoch 18/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 660.2993 - val_loss: 343.2322\n",
      "Epoch 19/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 540.8923 - val_loss: 324.5467\n",
      "Epoch 20/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 612.5091 - val_loss: 341.3675\n",
      "Epoch 21/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 588.6723 - val_loss: 321.2351\n",
      "Epoch 22/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 488.9198 - val_loss: 326.8230\n",
      "Epoch 23/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 569.4064 - val_loss: 332.2836\n",
      "Epoch 24/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 707.5074 - val_loss: 331.4402\n",
      "Epoch 25/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 581.9826 - val_loss: 318.9403\n",
      "Epoch 26/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 500.6990 - val_loss: 318.6512\n",
      "Epoch 27/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 644.6124 - val_loss: 323.2760\n",
      "Epoch 28/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 621.5174 - val_loss: 314.7272\n",
      "Epoch 29/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 644.5832 - val_loss: 325.6491\n",
      "Epoch 30/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 754.2162 - val_loss: 300.2833\n",
      "Epoch 31/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 499.7218 - val_loss: 309.1283\n",
      "Epoch 32/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 532.3411 - val_loss: 317.7538\n",
      "Epoch 33/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 792.4625 - val_loss: 307.1453\n",
      "Epoch 34/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 614.2505 - val_loss: 297.3499\n",
      "Epoch 35/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 588.9564 - val_loss: 309.1781\n",
      "Epoch 36/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 494.5605 - val_loss: 299.7976\n",
      "Epoch 37/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 512.7897 - val_loss: 302.8754\n",
      "Epoch 38/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 549.9138 - val_loss: 300.6097\n",
      "Epoch 39/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 454.6658 - val_loss: 293.6084\n",
      "Epoch 40/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 788.8079 - val_loss: 323.5207\n",
      "Epoch 41/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 644.7689 - val_loss: 279.6021\n",
      "Epoch 42/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 607.0873 - val_loss: 321.0165\n",
      "Epoch 43/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 600.0905 - val_loss: 288.7585\n",
      "Epoch 44/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 541.3608 - val_loss: 285.3567\n",
      "Epoch 45/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 693.3513 - val_loss: 306.4514\n",
      "Epoch 46/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 722.0301 - val_loss: 284.4314\n",
      "Epoch 47/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 712.1111 - val_loss: 276.2334\n",
      "Epoch 48/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 438.8869 - val_loss: 285.7912\n",
      "Epoch 49/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 548.7916 - val_loss: 281.9358\n",
      "Epoch 50/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 433.6034 - val_loss: 294.1696\n",
      "Epoch 51/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 527.7417 - val_loss: 278.6920\n",
      "Epoch 52/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 676.8535 - val_loss: 271.9738\n",
      "Epoch 53/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 631.3370 - val_loss: 275.9772\n",
      "Epoch 54/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 490.1745 - val_loss: 278.4913\n",
      "Epoch 55/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 640.9258 - val_loss: 283.8776\n",
      "Epoch 56/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 600.2332 - val_loss: 272.0418\n",
      "Epoch 57/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 616.5394 - val_loss: 266.3619\n",
      "Epoch 58/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 581.6318 - val_loss: 281.0515\n",
      "Epoch 59/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 576.3778 - val_loss: 271.9325\n",
      "Epoch 60/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 471.6396 - val_loss: 270.9560\n",
      "Epoch 61/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 612.1990 - val_loss: 288.2576\n",
      "Epoch 62/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 493.4568 - val_loss: 257.1478\n",
      "Epoch 63/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 778.3864 - val_loss: 270.4206\n",
      "Epoch 64/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 532.5108 - val_loss: 261.3118\n",
      "Epoch 65/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 642.5904 - val_loss: 265.4028\n",
      "Epoch 66/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 490.7799 - val_loss: 263.3771\n",
      "Epoch 67/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 640.2756 - val_loss: 262.3806\n",
      "Epoch 68/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 678.2241 - val_loss: 259.7480\n",
      "Epoch 69/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 550.6774 - val_loss: 265.0214\n",
      "Epoch 70/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 653.0927 - val_loss: 253.0920\n",
      "Epoch 71/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 798.6702 - val_loss: 256.0045\n",
      "Epoch 72/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 552.5498 - val_loss: 253.4683\n",
      "Epoch 73/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 809.8387 - val_loss: 294.7954\n",
      "Epoch 74/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 587.9572 - val_loss: 240.7751\n",
      "Epoch 75/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 492.7843 - val_loss: 261.4952\n",
      "Epoch 76/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 663.7673 - val_loss: 259.8098\n",
      "Epoch 77/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 466.6840 - val_loss: 249.5213\n",
      "Epoch 78/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 536.5838 - val_loss: 262.2055\n",
      "Epoch 79/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 455.9307 - val_loss: 242.5920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 564.7727 - val_loss: 285.6088\n",
      "Epoch 81/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 529.1268 - val_loss: 248.4971\n",
      "Epoch 82/400\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 594.7267 - val_loss: 260.8669\n",
      "Epoch 83/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 551.5366 - val_loss: 255.0631\n",
      "Epoch 84/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 487.9480 - val_loss: 243.5979\n",
      "Epoch 85/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 459.3317 - val_loss: 260.2370\n",
      "Epoch 86/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 503.4369 - val_loss: 258.7243\n",
      "Epoch 87/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 639.8460 - val_loss: 252.4713\n",
      "Epoch 88/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 619.9210 - val_loss: 258.5987\n",
      "Epoch 89/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 528.2496 - val_loss: 241.9831\n",
      "Epoch 90/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 500.9068 - val_loss: 243.8605\n",
      "Epoch 91/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 475.0652 - val_loss: 239.6146\n",
      "Epoch 92/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 606.8574 - val_loss: 265.8729\n",
      "Epoch 93/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 540.1626 - val_loss: 237.7745\n",
      "Epoch 94/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 515.5166 - val_loss: 267.2507\n",
      "Epoch 95/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 542.4479 - val_loss: 234.9620\n",
      "Epoch 96/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 748.7023 - val_loss: 254.6573\n",
      "Epoch 97/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 497.7222 - val_loss: 254.8310\n",
      "Epoch 98/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 546.3107 - val_loss: 242.2163\n",
      "Epoch 99/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 537.6376 - val_loss: 244.4315\n",
      "Epoch 100/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 552.7600 - val_loss: 245.0968\n",
      "Epoch 101/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 552.7642 - val_loss: 229.8233\n",
      "Epoch 102/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 532.9525 - val_loss: 245.5239\n",
      "Epoch 103/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 513.8848 - val_loss: 254.8270\n",
      "Epoch 104/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 542.5246 - val_loss: 239.8255\n",
      "Epoch 105/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 441.2374 - val_loss: 247.1738\n",
      "Epoch 106/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 639.1952 - val_loss: 247.4132\n",
      "Epoch 107/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 491.2911 - val_loss: 231.7659\n",
      "Epoch 108/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 781.3380 - val_loss: 279.5940\n",
      "Epoch 109/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 550.7289 - val_loss: 228.3654\n",
      "Epoch 110/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 442.1700 - val_loss: 244.9045\n",
      "Epoch 111/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 435.8505 - val_loss: 249.9191\n",
      "Epoch 112/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 468.2991 - val_loss: 252.8315\n",
      "Epoch 113/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 481.2546 - val_loss: 255.4857\n",
      "Epoch 114/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 492.2220 - val_loss: 233.4419\n",
      "Epoch 115/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 555.0029 - val_loss: 255.0958\n",
      "Epoch 116/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 651.6942 - val_loss: 259.1532\n",
      "Epoch 117/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 512.0364 - val_loss: 224.8643\n",
      "Epoch 118/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 686.4382 - val_loss: 257.2723\n",
      "Epoch 119/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 589.6242 - val_loss: 222.3680\n",
      "Epoch 120/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 596.5503 - val_loss: 258.5766\n",
      "Epoch 121/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 732.7805 - val_loss: 249.6201\n",
      "Epoch 122/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 458.9062 - val_loss: 229.6255\n",
      "Epoch 123/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 556.4774 - val_loss: 266.5127\n",
      "Epoch 124/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 521.5025 - val_loss: 239.1447\n",
      "Epoch 125/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 578.0354 - val_loss: 258.7429\n",
      "Epoch 126/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 599.8045 - val_loss: 237.6145\n",
      "Epoch 127/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 525.9985 - val_loss: 248.5819\n",
      "Epoch 128/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 436.0253 - val_loss: 228.0452\n",
      "Epoch 129/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 510.6430 - val_loss: 234.7024\n",
      "Epoch 130/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 516.5326 - val_loss: 235.0087\n",
      "Epoch 131/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 482.8649 - val_loss: 242.1019\n",
      "Epoch 132/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 662.5153 - val_loss: 238.2136\n",
      "Epoch 133/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 554.1679 - val_loss: 242.0341\n",
      "Epoch 134/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 574.0432 - val_loss: 253.8174\n",
      "Epoch 135/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 482.5190 - val_loss: 246.5516\n",
      "Epoch 136/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 471.5089 - val_loss: 250.3746\n",
      "Epoch 137/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 662.0792 - val_loss: 264.9408\n",
      "Epoch 138/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 509.7748 - val_loss: 223.5904\n",
      "Epoch 139/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 555.7215 - val_loss: 260.9592\n",
      "Epoch 140/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 531.3811 - val_loss: 238.2516\n",
      "Epoch 141/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 514.2144 - val_loss: 240.1936\n",
      "Epoch 142/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 670.7483 - val_loss: 235.5403\n",
      "Epoch 143/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 689.7190 - val_loss: 228.5632\n",
      "Epoch 144/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 479.4432 - val_loss: 237.8468\n",
      "Epoch 145/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 554.9961 - val_loss: 236.4905\n",
      "Epoch 146/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 525.2971 - val_loss: 246.5609\n",
      "Epoch 147/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 585.3570 - val_loss: 242.2434\n",
      "Epoch 148/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 585.3839 - val_loss: 247.4106\n",
      "Epoch 149/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 603.0686 - val_loss: 241.7063\n",
      "Epoch 150/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 611.0666 - val_loss: 235.7142\n",
      "Epoch 151/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 502.1852 - val_loss: 236.6117\n",
      "Epoch 152/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 527.0706 - val_loss: 236.4551\n",
      "Epoch 153/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 586.7858 - val_loss: 241.9130\n",
      "Epoch 154/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 511.3922 - val_loss: 246.0955\n",
      "Epoch 155/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 618.6076 - val_loss: 231.2891\n",
      "Epoch 156/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 474.3143 - val_loss: 227.1661\n",
      "Epoch 157/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 579.7581 - val_loss: 278.8857\n",
      "Epoch 158/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 615.7423 - val_loss: 228.7198\n",
      "Epoch 159/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 422.1569 - val_loss: 225.1280\n",
      "Epoch 160/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 468.3843 - val_loss: 275.3128\n",
      "Epoch 161/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 568.0227 - val_loss: 229.6811\n",
      "Epoch 162/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 546.4661 - val_loss: 250.3261\n",
      "Epoch 163/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 642.5265 - val_loss: 239.5490\n",
      "Epoch 164/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 681.4562 - val_loss: 248.1374\n",
      "Epoch 165/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 654.7367 - val_loss: 231.3927\n",
      "Epoch 166/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 524.3512 - val_loss: 230.6784\n",
      "Epoch 167/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 653.8525 - val_loss: 251.7843\n",
      "Epoch 168/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 486.7005 - val_loss: 231.9866\n",
      "Epoch 169/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 472.1517 - val_loss: 234.7979\n",
      "Epoch 170/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 474.7645 - val_loss: 243.7530\n",
      "Epoch 171/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 701.8052 - val_loss: 239.6352\n",
      "Epoch 172/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 558.3964 - val_loss: 234.9161\n",
      "Epoch 173/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 464.5315 - val_loss: 244.1682\n",
      "Epoch 174/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 505.2608 - val_loss: 243.9788\n",
      "Epoch 175/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 620.5879 - val_loss: 233.4891\n",
      "Epoch 176/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 590.9480 - val_loss: 234.3599\n",
      "Epoch 177/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 733.6702 - val_loss: 240.4812\n",
      "Epoch 178/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 565.3799 - val_loss: 236.1792\n",
      "Epoch 179/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 728.2321 - val_loss: 242.7195\n",
      "Epoch 180/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 625.8301 - val_loss: 227.6059\n",
      "Epoch 181/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 520.7936 - val_loss: 238.6774\n",
      "Epoch 182/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 655.2900 - val_loss: 241.3750\n",
      "Epoch 183/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 590.8876 - val_loss: 246.9031\n",
      "Epoch 184/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 460.2137 - val_loss: 226.4573\n",
      "Epoch 185/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 612.6569 - val_loss: 251.3954\n",
      "Epoch 186/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 480.2284 - val_loss: 235.5432\n",
      "Epoch 187/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 559.8672 - val_loss: 248.3563\n",
      "Epoch 188/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 496.3208 - val_loss: 227.0499\n",
      "Epoch 189/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 530.0742 - val_loss: 239.5256\n",
      "Epoch 190/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 488.8180 - val_loss: 236.5379\n",
      "Epoch 191/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 459.4011 - val_loss: 244.2143\n",
      "Epoch 192/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 537.9587 - val_loss: 253.3648\n",
      "Epoch 193/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 507.1925 - val_loss: 223.5648\n",
      "Epoch 194/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 539.8550 - val_loss: 249.4764\n",
      "Epoch 195/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 612.8060 - val_loss: 239.1121\n",
      "Epoch 196/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 544.2652 - val_loss: 244.9200\n",
      "Epoch 197/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 515.7882 - val_loss: 235.4485\n",
      "Epoch 198/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 579.8102 - val_loss: 251.1271\n",
      "Epoch 199/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 546.2297 - val_loss: 236.7555\n",
      "Epoch 200/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 450.6833 - val_loss: 240.6087\n",
      "Epoch 201/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 537.9567 - val_loss: 242.6624\n",
      "Epoch 202/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 619.4921 - val_loss: 232.7910\n",
      "Epoch 203/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 749.3802 - val_loss: 260.5631\n",
      "Epoch 204/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 589.4091 - val_loss: 226.6161\n",
      "Epoch 205/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 553.7220 - val_loss: 244.8069\n",
      "Epoch 206/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 460.3735 - val_loss: 240.0870\n",
      "Epoch 207/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 534.0353 - val_loss: 246.4217\n",
      "Epoch 208/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 405.9644 - val_loss: 228.6613\n",
      "Epoch 209/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 589.1121 - val_loss: 305.4450\n",
      "Epoch 210/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 565.6381 - val_loss: 226.1381\n",
      "Epoch 211/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 411.5051 - val_loss: 230.5747\n",
      "Epoch 212/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 573.1738 - val_loss: 243.0948\n",
      "Epoch 213/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 524.2635 - val_loss: 243.9774\n",
      "Epoch 214/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 587.6947 - val_loss: 239.0033\n",
      "Epoch 215/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 586.1935 - val_loss: 228.6616\n",
      "Epoch 216/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 503.1136 - val_loss: 244.3204\n",
      "Epoch 217/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 577.6092 - val_loss: 248.8323\n",
      "Epoch 218/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 544.2322 - val_loss: 240.0795\n",
      "Epoch 219/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 555.8437 - val_loss: 234.4907\n",
      "Epoch 220/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 563.7677 - val_loss: 255.8711\n",
      "Epoch 221/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 706.8111 - val_loss: 226.1286\n",
      "Epoch 222/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 619.0377 - val_loss: 228.9260\n",
      "Epoch 223/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 726.6485 - val_loss: 231.5229\n",
      "Epoch 224/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 723.2337 - val_loss: 238.5740\n",
      "Epoch 225/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 617.0417 - val_loss: 249.8255\n",
      "Epoch 226/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 456.4348 - val_loss: 243.6741\n",
      "Epoch 227/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 550.7467 - val_loss: 239.2759\n",
      "Epoch 228/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 532.4438 - val_loss: 224.9159\n",
      "Epoch 229/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 511.7697 - val_loss: 227.5312\n",
      "Epoch 230/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 539.3004 - val_loss: 231.7564\n",
      "Epoch 231/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 625.3760 - val_loss: 252.1957\n",
      "Epoch 232/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 638.0564 - val_loss: 227.7242\n",
      "Epoch 233/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 467.0079 - val_loss: 226.3697\n",
      "Epoch 234/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 494.1121 - val_loss: 250.7432\n",
      "Epoch 235/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 421.7853 - val_loss: 231.6127\n",
      "Epoch 236/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 519.5797 - val_loss: 241.7101\n",
      "Epoch 237/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 532.5421 - val_loss: 237.4332\n",
      "Epoch 238/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 497.7608 - val_loss: 240.3522\n",
      "Epoch 239/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 553.1228 - val_loss: 257.2333\n",
      "Epoch 240/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 583.7861 - val_loss: 230.0960\n",
      "Epoch 241/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 664.7050 - val_loss: 227.5048\n",
      "Epoch 242/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 548.3312 - val_loss: 255.7527\n",
      "Epoch 243/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 509.0879 - val_loss: 222.5518\n",
      "Epoch 244/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 595.3293 - val_loss: 234.0321\n",
      "Epoch 245/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 679.1608 - val_loss: 232.0875\n",
      "Epoch 246/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 508.0172 - val_loss: 222.4098\n",
      "Epoch 247/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 572.5665 - val_loss: 237.5342\n",
      "Epoch 248/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 495.0120 - val_loss: 244.5499\n",
      "Epoch 249/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 460.7305 - val_loss: 236.3099\n",
      "Epoch 250/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 528.4888 - val_loss: 228.4129\n",
      "Epoch 251/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 655.5044 - val_loss: 254.8952\n",
      "Epoch 252/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 516.0222 - val_loss: 224.5831\n",
      "Epoch 253/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 499.1862 - val_loss: 245.0556\n",
      "Epoch 254/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 476.0634 - val_loss: 247.0892\n",
      "Epoch 255/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 640.7719 - val_loss: 231.6367\n",
      "Epoch 256/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 412.4516 - val_loss: 229.0529\n",
      "Epoch 257/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 684.3572 - val_loss: 279.1486\n",
      "Epoch 258/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 596.7493 - val_loss: 226.2102\n",
      "Epoch 259/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 469.0147 - val_loss: 238.0661\n",
      "Epoch 260/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 495.2143 - val_loss: 259.0727\n",
      "Epoch 261/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 632.4488 - val_loss: 221.4292\n",
      "Epoch 262/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 650.9580 - val_loss: 221.8894\n",
      "Epoch 263/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 529.2545 - val_loss: 230.2152\n",
      "Epoch 264/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 446.6709 - val_loss: 237.9176\n",
      "Epoch 265/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 516.2275 - val_loss: 236.1230\n",
      "Epoch 266/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 588.5415 - val_loss: 234.1404\n",
      "Epoch 267/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 501.0765 - val_loss: 237.3538\n",
      "Epoch 268/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 478.6512 - val_loss: 229.0569\n",
      "Epoch 269/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 527.5024 - val_loss: 228.0072\n",
      "Epoch 270/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 452.6018 - val_loss: 250.2914\n",
      "Epoch 271/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 549.6414 - val_loss: 231.0120\n",
      "Epoch 272/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 510.3842 - val_loss: 231.6067\n",
      "Epoch 273/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 567.9507 - val_loss: 247.5133\n",
      "Epoch 274/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 531.0300 - val_loss: 235.7597\n",
      "Epoch 275/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 566.4688 - val_loss: 243.7979\n",
      "Epoch 276/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 617.8922 - val_loss: 240.1798\n",
      "Epoch 277/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 650.4830 - val_loss: 235.0850\n",
      "Epoch 278/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 725.3625 - val_loss: 239.3110\n",
      "Epoch 279/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 587.7262 - val_loss: 235.4725\n",
      "Epoch 280/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 441.8749 - val_loss: 230.2845\n",
      "Epoch 281/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 531.3138 - val_loss: 257.8194\n",
      "Epoch 282/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 679.5281 - val_loss: 236.9555\n",
      "Epoch 283/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 475.7268 - val_loss: 223.4445\n",
      "Epoch 284/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 580.0707 - val_loss: 249.3226\n",
      "Epoch 285/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 504.4285 - val_loss: 217.3142\n",
      "Epoch 286/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 659.2964 - val_loss: 262.0209\n",
      "Epoch 287/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 541.6127 - val_loss: 230.4868\n",
      "Epoch 288/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 530.6008 - val_loss: 241.1329\n",
      "Epoch 289/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 549.3459 - val_loss: 242.6109\n",
      "Epoch 290/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 541.8068 - val_loss: 236.5084\n",
      "Epoch 291/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 538.5082 - val_loss: 239.0802\n",
      "Epoch 292/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 537.0522 - val_loss: 221.8071\n",
      "Epoch 293/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 626.9331 - val_loss: 248.5037\n",
      "Epoch 294/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 657.6569 - val_loss: 229.0994\n",
      "Epoch 295/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 582.4005 - val_loss: 226.6001\n",
      "Epoch 296/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 562.1786 - val_loss: 242.7528\n",
      "Epoch 297/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 649.6377 - val_loss: 243.3043\n",
      "Epoch 298/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 528.0099 - val_loss: 238.6857\n",
      "Epoch 299/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 474.0374 - val_loss: 247.5348\n",
      "Epoch 300/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 687.3380 - val_loss: 242.1556\n",
      "Epoch 301/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 568.6748 - val_loss: 221.1909\n",
      "Epoch 302/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 367.8521 - val_loss: 249.9039\n",
      "Epoch 303/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 529.9047 - val_loss: 242.9129\n",
      "Epoch 304/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 629.4418 - val_loss: 234.7083\n",
      "Epoch 305/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 655.2581 - val_loss: 243.8619\n",
      "Epoch 306/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 618.2314 - val_loss: 232.1025\n",
      "Epoch 307/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 619.2880 - val_loss: 241.7004\n",
      "Epoch 308/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 677.9603 - val_loss: 232.8619\n",
      "Epoch 309/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 526.2175 - val_loss: 229.5023\n",
      "Epoch 310/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 523.8881 - val_loss: 229.0585\n",
      "Epoch 311/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 523.7614 - val_loss: 241.1197\n",
      "Epoch 312/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 554.5324 - val_loss: 241.1713\n",
      "Epoch 313/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 618.8172 - val_loss: 240.4499\n",
      "Epoch 314/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 612.6214 - val_loss: 237.6936\n",
      "Epoch 315/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 658.7882 - val_loss: 237.3372\n",
      "Epoch 316/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 493.4577 - val_loss: 227.7450\n",
      "Epoch 317/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 639.4624 - val_loss: 246.5554\n",
      "Epoch 318/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 376.7039 - val_loss: 229.6121\n",
      "Epoch 319/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 568.0823 - val_loss: 267.5465\n",
      "Epoch 320/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 440.6980 - val_loss: 219.8755\n",
      "Epoch 321/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 648.5239 - val_loss: 245.5096\n",
      "Epoch 322/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 605.9400 - val_loss: 257.7093\n",
      "Epoch 323/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 584.6001 - val_loss: 225.8129\n",
      "Epoch 324/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 839.9105 - val_loss: 238.4588\n",
      "Epoch 325/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 508.3708 - val_loss: 227.1654\n",
      "Epoch 326/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 689.7156 - val_loss: 267.6775\n",
      "Epoch 327/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 668.6999 - val_loss: 220.5391\n",
      "Epoch 328/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 464.4360 - val_loss: 227.9358\n",
      "Epoch 329/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 584.8628 - val_loss: 264.7696\n",
      "Epoch 330/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 511.4973 - val_loss: 221.3448\n",
      "Epoch 331/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 401.7748 - val_loss: 245.2175\n",
      "Epoch 332/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 575.1202 - val_loss: 264.9770\n",
      "Epoch 333/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 510.7550 - val_loss: 225.3366\n",
      "Epoch 334/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 590.8785 - val_loss: 235.5025\n",
      "Epoch 335/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 520.3409 - val_loss: 235.1811\n",
      "Epoch 336/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 587.9323 - val_loss: 257.8644\n",
      "Epoch 337/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 519.4719 - val_loss: 232.6804\n",
      "Epoch 338/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 512.8678 - val_loss: 234.3903\n",
      "Epoch 339/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 553.0961 - val_loss: 254.7077\n",
      "Epoch 340/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 489.3202 - val_loss: 224.4576\n",
      "Epoch 341/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 430.9787 - val_loss: 249.5003\n",
      "Epoch 342/400\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 431.0425 - val_loss: 239.4108\n",
      "Epoch 343/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 445.9808 - val_loss: 244.1427\n",
      "Epoch 344/400\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 521.1260 - val_loss: 234.8802\n",
      "Epoch 345/400\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 653.6041 - val_loss: 254.3654\n",
      "Epoch 346/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 627.5081 - val_loss: 225.0523\n",
      "Epoch 347/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 594.3352 - val_loss: 235.0179\n",
      "Epoch 348/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 514.5308 - val_loss: 235.3013\n",
      "Epoch 349/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 455.6806 - val_loss: 234.5533\n",
      "Epoch 350/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 616.6632 - val_loss: 228.7991\n",
      "Epoch 351/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 713.6440 - val_loss: 244.6269\n",
      "Epoch 352/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 491.0466 - val_loss: 249.3652\n",
      "Epoch 353/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 640.0872 - val_loss: 251.5736\n",
      "Epoch 354/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 534.3630 - val_loss: 222.6297\n",
      "Epoch 355/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 567.1459 - val_loss: 252.5565\n",
      "Epoch 356/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 535.9772 - val_loss: 232.7607\n",
      "Epoch 357/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 510.8127 - val_loss: 232.5813\n",
      "Epoch 358/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 472.5376 - val_loss: 245.8309\n",
      "Epoch 359/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 598.3930 - val_loss: 247.2905\n",
      "Epoch 360/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 651.8373 - val_loss: 228.5641\n",
      "Epoch 361/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 600.4354 - val_loss: 234.3200\n",
      "Epoch 362/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 700.5809 - val_loss: 232.5298\n",
      "Epoch 363/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 532.6325 - val_loss: 231.9960\n",
      "Epoch 364/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 572.9164 - val_loss: 257.9703\n",
      "Epoch 365/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 647.8521 - val_loss: 233.9829\n",
      "Epoch 366/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 495.4070 - val_loss: 247.1657\n",
      "Epoch 367/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 519.3630 - val_loss: 252.5281\n",
      "Epoch 368/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 600.7636 - val_loss: 242.4932\n",
      "Epoch 369/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 475.1784 - val_loss: 224.4541\n",
      "Epoch 370/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 504.3975 - val_loss: 239.8373\n",
      "Epoch 371/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 477.2917 - val_loss: 243.2274\n",
      "Epoch 372/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 455.4202 - val_loss: 272.0845\n",
      "Epoch 373/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 637.4945 - val_loss: 238.5865\n",
      "Epoch 374/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 477.5817 - val_loss: 228.1846\n",
      "Epoch 375/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 582.9771 - val_loss: 239.7551\n",
      "Epoch 376/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 517.9976 - val_loss: 242.1837\n",
      "Epoch 377/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 461.5072 - val_loss: 234.2402\n",
      "Epoch 378/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 611.3788 - val_loss: 246.6696\n",
      "Epoch 379/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 665.7652 - val_loss: 239.6522\n",
      "Epoch 380/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 506.1678 - val_loss: 237.5298\n",
      "Epoch 381/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 703.9499 - val_loss: 247.9733\n",
      "Epoch 382/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 507.3495 - val_loss: 226.9203\n",
      "Epoch 383/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 781.7672 - val_loss: 250.0672\n",
      "Epoch 384/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 590.3671 - val_loss: 221.6038\n",
      "Epoch 385/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 607.5320 - val_loss: 257.3767\n",
      "Epoch 386/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 663.8731 - val_loss: 234.2853\n",
      "Epoch 387/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 595.5547 - val_loss: 246.4990\n",
      "Epoch 388/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 546.6161 - val_loss: 229.8323\n",
      "Epoch 389/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 574.3624 - val_loss: 234.3776\n",
      "Epoch 390/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 501.0121 - val_loss: 252.8757\n",
      "Epoch 391/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 509.7349 - val_loss: 256.9089\n",
      "Epoch 392/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 402.5722 - val_loss: 217.5809\n",
      "Epoch 393/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 375.6079 - val_loss: 247.4520\n",
      "Epoch 394/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 566.2531 - val_loss: 300.2348\n",
      "Epoch 395/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 496.7275 - val_loss: 223.1596\n",
      "Epoch 396/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 667.2198 - val_loss: 236.9274\n",
      "Epoch 397/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 612.7029 - val_loss: 223.5682\n",
      "Epoch 398/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 697.8765 - val_loss: 240.7183\n",
      "Epoch 399/400\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 557.9191 - val_loss: 244.3849\n",
      "Epoch 400/400\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 441.6512 - val_loss: 233.1105\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 33,537\n",
      "Trainable params: 33,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Fitting  model to data.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=32,epochs=400)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Loss\n",
    "\n",
    "Loss of training and validation is very crucial for every Neural Network. In reality, during training, it is a clue that tells us whether or not our model suits as planned. A history feature of the Keras model provides a plot for losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracy\n",
    "\n",
    "To verify our model's accuracy, we measure mean squared error and mean absolute errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "The mean_squared_error function computes mean square error,\n",
    "a risk metric corresponding to the expected value of the squared (quadratic) error or loss [10].\n",
    "### Mean Absolute Error\n",
    "The mean_absolute_error function computes mean absolute error, a risk metric corresponding to the expected value of the absolute error loss or -norm loss [10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared = 15.267956389507487\n",
      "Absolute = 11.225650628406973\n"
     ]
    }
   ],
   "source": [
    "# Calculatting errors \n",
    "predictions = model.predict(X_test)\n",
    "# mean squared error\n",
    "print(\"Squared =\" ,np.sqrt(mean_squared_error(y_test,predictions)))\n",
    "# mean absolute error\n",
    "print(\"Absolute =\",mean_absolute_error(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "We have to save it in.h5 format to use this model on a Flask server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to use in flask server.\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] https://keras.io/about/\n",
    "\n",
    "Keras Regression Tutorial\n",
    "\n",
    "[2] https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "How to make predictions using Keras Regression\n",
    "\n",
    "[3] https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\n",
    "\n",
    "[4] https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "Artificial Neural Networks\n",
    "https://web.microsoftstream.com/video/b3c0a6ba-86b6-4f4a-bc1d-48d26c868bea\n",
    "\n",
    "Weights and biases\n",
    "https://web.microsoftstream.com/video/89718bf7-173b-4c24-8922-a81b31296f7e\n",
    "\n",
    "Building a neuron\n",
    "https://web.microsoftstream.com/video/85a3874f-778a-45b2-9b41-f3b525fe9549\n",
    "\n",
    "Neurons in keras\n",
    "https://web.microsoftstream.com/video/7ffcdaef-72ef-4ad1-96c3-acc92f8e184d?list=studio\n",
    "\n",
    "[5] https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html\n",
    "\n",
    "[6] https://keras.io/guides/sequential_model/\n",
    "\n",
    "[7] https://keras.io/api/layers/\n",
    "\n",
    "[8] https://keras.io/api/optimizers/\n",
    "\n",
    "[9] https://keras.io/api/optimizers/adam/\n",
    "\n",
    "[10] https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error\n",
    "\n",
    "[11] https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
